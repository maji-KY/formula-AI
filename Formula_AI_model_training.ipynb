{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Formula AI モデル作成",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOldpKEzNxnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルと訓練データを置くGoogleDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwJ79lTQNxmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 訓練データを準備\n",
        "!unzip -q -d ./ '/gdrive/My Drive/Colab Notebooks/train_data.zip'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6mKae_EJ5Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optunaを使う権利をやろう\n",
        "!pip install optuna"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qly04VrkdoeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Formura AI用のデータ読み込みクラス\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import collections\n",
        "\n",
        "from keras.utils import Sequence\n",
        "\n",
        "frame_offset = 3 # 何フレーム先の状態をラベルに設定するか\n",
        "class_num = 12\n",
        "\n",
        "# ファイル名の連番とラベル値で時系列データを作ってるのだが、訳分からなくなってソースがカオス\n",
        "class F1Data(Sequence):\n",
        "  def __init__(self, batch_size, data_dir, is_video, frame_num=5, limit=0):\n",
        "    if not batch_size > frame_num + frame_offset:\n",
        "      raise ValueError('batch_size must be greater than %d' % (frame_num + frame_offset))\n",
        "    self.batch_size = batch_size\n",
        "    self.frame_num = frame_num\n",
        "    self.data_total_count = len(os.listdir(data_dir))\n",
        "    self.data_dir = data_dir\n",
        "    self.is_video = is_video\n",
        "    self.split_num = math.ceil(self.data_total_count / batch_size) if limit == 0 else limit\n",
        "    print('data_dir: %s, data_total_count=%s, split_num=%s' % (data_dir, self.data_total_count, self.split_num))\n",
        "    self.all_file_data = sorted([self.data_tuple(file_name) for file_name in os.listdir(self.data_dir)], key=lambda x: x[0])\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.make_input_and_label(idx)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.split_num\n",
        "  \n",
        "  def read_image(self, data_dir, file_name):\n",
        "    return np.array(Image.open('%s/%s' % (data_dir, file_name)))\n",
        "\n",
        "  def data_tuple(self, file_name):\n",
        "    [count, rest] = file_name.split('_')\n",
        "    state = rest.split('.')[0]\n",
        "    return (int(count), int(state), file_name)\n",
        "\n",
        "  def grouped(self, collection, num):\n",
        "    return zip(*[collection[x:] for x in range(num)])\n",
        "\n",
        "  def labeled(self, data):\n",
        "    frames = [x[2] for x in data][:self.frame_num]\n",
        "    concat_frames = np.stack(frames) if self.is_video else frames[self.frame_num - 1]\n",
        "    label = data[-1][1]\n",
        "    one_hot_label = np.identity(class_num)[label]\n",
        "    return (concat_frames, one_hot_label)\n",
        "\n",
        "  def make_input_and_label(self, seq_index):\n",
        "    load_from_idx = (self.batch_size * seq_index) - self.frame_num\n",
        "    load_from_idx = load_from_idx if load_from_idx > 0 else 0\n",
        "    image_data = [(x[0], x[1], self.read_image(self.data_dir, x[2])) for x in self.all_file_data[load_from_idx:self.batch_size*(seq_index+1)]]\n",
        "    grouped_data = self.grouped(image_data, self.frame_num + frame_offset)\n",
        "    labeled_data = [self.labeled(x) for x in grouped_data]\n",
        "    [inpus, labels] = zip(*labeled_data)\n",
        "    return np.stack(inpus), np.stack(labels)\n",
        "  \n",
        "  def get_class_weight(self):\n",
        "    count_data = collections.Counter([x[1] for x in self.all_file_data])\n",
        "    max_class_count = max(count_data.values())\n",
        "    return {i: 1 / (count_data[i] / max_class_count) for i in range(class_num)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP7Epn0mmBL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Formura AI用のモデルを作成して保存\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend\n",
        "from keras import applications\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 1\n",
        "tf.set_random_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "class_num = 12\n",
        "\n",
        "# 画像の識別の訓練\n",
        "def build_cnn_model(): # MobileNet\n",
        "  model_input = Input(shape=(224, 224, 3), name='input', dtype='float32')\n",
        "  base_model = applications.MobileNetV2(input_shape=(224, 224, 3), alpha=1.0, pooling='avg', include_top=False, weights='imagenet')\n",
        "  net = base_model(model_input)\n",
        "  logits = Dense(class_num, activation='softmax', name='logits')(net)\n",
        "  model = Model(inputs=model_input, outputs=logits)\n",
        "  return model\n",
        "\n",
        "def cnn_train():\n",
        "  backend.tensorflow_backend.clear_session()\n",
        "\n",
        "  is_continue = False\n",
        "  if is_continue:\n",
        "    model = load_model('/gdrive/My Drive/Colab Notebooks/fai/cnn_model.009-0.778.h5', compile=False)\n",
        "    initial_epoch = 9\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=Adam(lr=1e-3, beta_1=0.9, beta_2=0.999),\n",
        "              optimizer=SGD(lr=5e-5, momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])\n",
        "  else:\n",
        "    model = build_cnn_model()\n",
        "    initial_epoch = 0\n",
        "    # SGD(lr=0.00005, momentum=0.9, nesterov=True)\n",
        "    # Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=SGD(lr=0.00005, momentum=0.9, nesterov=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  \n",
        "  epochs = 500\n",
        "  \n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=1)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=1e-15)\n",
        "  model_cp = ModelCheckpoint('/gdrive/My Drive/Colab Notebooks/fai/cnn_model.{epoch:03d}-{val_loss:.3f}.h5', monitor='val_loss', verbose=0, save_best_only=False, mode='auto', period=1)\n",
        "\n",
        "  train_data = F1Data(batch_size=60, data_dir='train_data/data_1', is_video=False, limit=0)\n",
        "  class_weight = train_data.get_class_weight()\n",
        "  val_data = F1Data(batch_size=60, data_dir='train_data/data_2', is_video=False, limit=0)\n",
        "  \n",
        "  hist = model.fit_generator(generator=train_data,\n",
        "                   epochs=epochs,\n",
        "                   initial_epoch=initial_epoch,\n",
        "                   validation_data=val_data,\n",
        "                   class_weight=class_weight,\n",
        "                   max_queue_size=10,\n",
        "                   use_multiprocessing=True, workers=4,\n",
        "                   callbacks=[early_stopping, reduce_lr, model_cp]\n",
        "                  )\n",
        "  \n",
        "  model.save('/gdrive/My Drive/Colab Notebooks/fai/cnn_model.h5', include_optimizer=False)\n",
        "  \n",
        "\n",
        "cnn_train()\n",
        "\n",
        "# 学習済みモデルの評価\n",
        "def cnn_evaluate():\n",
        "  val_inputs1, val_labels1 = F1Data(batch_size=3000, data_dir='train_data/data_2', is_video=False, limit=1)[0]\n",
        "  val_inputs2, val_labels2 = F1Data(batch_size=3000, data_dir='train_data/data_3', is_video=False, limit=1)[0]\n",
        "  def evaluate(model_path):\n",
        "    backend.tensorflow_backend.clear_session()\n",
        "    model = load_model(model_path)\n",
        "    print(model_path)\n",
        "    result = model.evaluate(val_inputs1, val_labels1)\n",
        "    print(result)\n",
        "    result = model.evaluate(val_inputs2, val_labels2)\n",
        "    print(result)\n",
        "  \n",
        "  model_dir = '/gdrive/My Drive/Colab Notebooks/fai'\n",
        "  for file_name in os.listdir(model_dir):\n",
        "    evaluate('%s/%s' % (model_dir, file_name))\n",
        "  \n",
        "cnn_evaluate()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VQAGstdJQNz",
        "colab_type": "text"
      },
      "source": [
        "# トレーニング結果\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input (InputLayer)           (None, 224, 224, 3)       0         \n",
        "_________________________________________________________________\n",
        "mobilenetv2_1.00_224 (Model) (None, 1280)              2257984   \n",
        "_________________________________________________________________\n",
        "logits (Dense)               (None, 12)                15372     \n",
        "=================================================================\n",
        "Total params: 2,273,356\n",
        "Trainable params: 2,239,244\n",
        "Non-trainable params: 34,112\n",
        "_________________________________________________________________\n",
        "data_dir: train_data/data_1, data_total_count=72000, split_num=1200\n",
        "\n",
        "data_dir: train_data/data_2, data_total_count=28849, split_num=481\n",
        "\n",
        "Epoch 10/500\n",
        "1200/1200 [==============================] - 928s 773ms/step - loss: 0.9279 - acc: 0.8070 - val_loss: 0.7905 - val_acc: 0.6796\n",
        "Epoch 11/500\n",
        "1200/1200 [==============================] - 923s 769ms/step - loss: 0.8353 - acc: 0.8240 - val_loss: 0.7991 - val_acc: 0.6741\n",
        "Epoch 12/500\n",
        "1200/1200 [==============================] - 922s 769ms/step - loss: 0.7519 - acc: 0.8376 - val_loss: 0.7868 - val_acc: 0.6819\n",
        "Epoch 13/500\n",
        "1200/1200 [==============================] - 933s 778ms/step - loss: 0.6768 - acc: 0.8522 - val_loss: 0.7989 - val_acc: 0.6850\n",
        "Epoch 14/500\n",
        "1200/1200 [==============================] - 933s 777ms/step - loss: 0.6091 - acc: 0.8659 - val_loss: 0.8133 - val_acc: 0.6837\n",
        "Epoch 15/500\n",
        "1200/1200 [==============================] - 922s 768ms/step - loss: 0.5479 - acc: 0.8797 - val_loss: 0.8228 - val_acc: 0.6792\n",
        "Epoch 16/500\n",
        "1200/1200 [==============================] - 923s 769ms/step - loss: 0.4931 - acc: 0.8919 - val_loss: 0.8293 - val_acc: 0.6865\n",
        "Epoch 17/500\n",
        "1200/1200 [==============================] - 924s 770ms/step - loss: 0.4413 - acc: 0.9038 - val_loss: 0.8423 - val_acc: 0.6862\n",
        "\n",
        "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
        "Epoch 18/500\n",
        "1200/1200 [==============================] - 924s 770ms/step - loss: 0.3802 - acc: 0.9201 - val_loss: 0.8415 - val_acc: 0.6879\n",
        "Epoch 19/500\n",
        "1200/1200 [==============================] - 922s 768ms/step - loss: 0.3698 - acc: 0.9223 - val_loss: 0.8434 - val_acc: 0.6883\n",
        "Epoch 20/500\n",
        "1200/1200 [==============================] - 918s 765ms/step - loss: 0.3642 - acc: 0.9237 - val_loss: 0.8460 - val_acc: 0.6873\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VHv4YbhVE0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 後半の部分の訓練のために静止画の特徴量をファイルに保存\n",
        "import tensorflow as tf\n",
        "from keras import backend\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "import numpy as np\n",
        "\n",
        "def save_features(save_path, data_dir):\n",
        "    backend.tensorflow_backend.clear_session()\n",
        "    \n",
        "    model = load_model('/gdrive/My Drive/Colab Notebooks/fai2/cnn_model.019-0.843.h5')\n",
        "    model = model.layers[1]\n",
        "    \n",
        "    print(model.inputs)\n",
        "#     model.summary()\n",
        "    \n",
        "    train_data = F1Data(batch_size=1000, data_dir=data_dir, is_video=False)\n",
        "    \n",
        "    feature_data = []\n",
        "    \n",
        "    for i in range(len(train_data)):\n",
        "      images, labels = train_data[i]\n",
        "      features = model.predict(images, verbose=1)\n",
        "      feature_data += zip(features, labels)\n",
        "    \n",
        "    np.save(save_path, feature_data)\n",
        "    \n",
        "    \n",
        "save_features('/gdrive/My Drive/Colab Notebooks/fai/feature_data_1', 'train_data/data_1') # 訓練用\n",
        "save_features('/gdrive/My Drive/Colab Notebooks/fai/feature_data_2', 'train_data/data_2') # 検証用"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKYT4S40xugl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 動画？の学習\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend\n",
        "from keras import applications\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, Layer, Conv1D, GlobalMaxPooling1D, BatchNormalization, Activation, Lambda, Dropout, LSTM\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import Sequence\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 2 # 1\n",
        "tf.set_random_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "class_num = 12\n",
        "\n",
        "# FeatureData\n",
        "class FeatureData(Sequence):\n",
        "  def __init__(self, batch_size, data_path, frame_num=15):\n",
        "    self.batch_size = batch_size\n",
        "    self.frame_num = frame_num\n",
        "    self.feature_data = np.load(data_path, allow_pickle=True)\n",
        "    self.split_num = math.ceil(len(self.feature_data) / batch_size)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch = self.feature_data[idx*self.batch_size:(idx+1)*self.batch_size+self.frame_num]\n",
        "    result_frames = []\n",
        "    result_labels = []\n",
        "    for j in range(len(batch) - self.frame_num):\n",
        "      current = batch[j:j+self.frame_num]\n",
        "      frames, labels = zip(*current)\n",
        "      result_frames.append(np.array(frames))\n",
        "      result_labels.append(np.array(labels[-1]))\n",
        "    return np.array(result_frames), np.array(result_labels)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.split_num\n",
        "\n",
        "# tuning\n",
        "import optuna\n",
        "\n",
        "def tuning():\n",
        "  backend.tensorflow_backend.clear_session()\n",
        "  \n",
        "  train_data = F1Data(batch_size=40, data_dir='train_data/data_1', frame_num=18, is_video=True, limit=300)\n",
        "  class_weight = train_data.get_class_weight()\n",
        "\n",
        "  train_feature = FeatureData(1000, '/gdrive/My Drive/Colab Notebooks/fai/feature_data_1.npy', frame_num=15)\n",
        "  val_feature = FeatureData(1000, '/gdrive/My Drive/Colab Notebooks/fai/feature_data_2.npy', frame_num=15)\n",
        "\n",
        "  \n",
        "  def objective(trial):\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    model_input = Input(shape=(None, 1280), name='input', dtype='float32')\n",
        "\n",
        "    net = TimeDistributed(Lambda(lambda x: x))(model_input)\n",
        "    \n",
        "    conv1_filters = trial.suggest_int('conv1_filters', 128, 384)\n",
        "    conv1_size = trial.suggest_int('conv1_size', 1, 3)\n",
        "    conv1_padding = trial.suggest_categorical('conv1_padding', ['same', 'causal'])\n",
        "\n",
        "    net = Conv1D(conv1_filters, conv1_size, padding=conv1_padding, kernel_initializer='he_normal')(net)\n",
        "    net = BatchNormalization(axis=2)(net)\n",
        "    net = Activation('relu')(net)\n",
        "    net = GlobalMaxPooling1D()(net)\n",
        "\n",
        "    logits = Dense(class_num, activation='softmax', name='logits')(net)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=logits)\n",
        "    \n",
        "#     model.summary()\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-3, beta_1=0.9, beta_2=0.999),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    print(trial.params)\n",
        "    epochs = 20\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
        "#     prune = optuna.integration.KerasPruningCallback(trial, 'val_loss')\n",
        "    \n",
        "    hist = model.fit_generator(\n",
        "        generator=train_feature,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_feature,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=2\n",
        "      )\n",
        "    \n",
        "    best_val = min(hist.history['val_loss'])\n",
        "\n",
        "    return best_val\n",
        "\n",
        "  study = optuna.create_study(direction='minimize')\n",
        "  study.optimize(objective, n_trials=150)\n",
        "\n",
        "  print('best_params: %s' % study.best_params)\n",
        "  print('best_value: %s' % study.best_value)\n",
        "  \n",
        "tuning()\n",
        "  \n",
        "\n",
        "# 各フレームの静止画の特徴量を時間軸で畳み込むやつ\n",
        "def build_1dcnn_model():\n",
        "  model_input = Input(shape=(None, 1280), name='input', dtype='float32')\n",
        "  \n",
        "  net = TimeDistributed(Lambda(lambda x: x))(model_input)\n",
        "  \n",
        "  net = Conv1D(226, 3, padding='same', kernel_initializer='he_normal')(net)\n",
        "  net = BatchNormalization(axis=2)(net)\n",
        "  net = Activation('relu')(net)\n",
        "  net = GlobalMaxPooling1D()(net)\n",
        "\n",
        "  logits = Dense(class_num, activation='softmax', name='logits')(net)\n",
        "  \n",
        "  model = Model(inputs=model_input, outputs=logits)\n",
        "  return model\n",
        "\n",
        "# train motion\n",
        "def train_motion():\n",
        "  backend.tensorflow_backend.clear_session()\n",
        "\n",
        "  model = build_1dcnn_model()\n",
        "  initial_epoch = 0\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-3, beta_1=0.9, beta_2=0.999),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  \n",
        "  epochs = 10\n",
        "  \n",
        "  model_cp = ModelCheckpoint('/gdrive/My Drive/Colab Notebooks/fai_motion/1dcnn_model.{epoch:03d}-{val_loss:.3f}.h5', monitor='val_loss', verbose=0, save_best_only=False, mode='auto', period=1)\n",
        "\n",
        "  train_data = F1Data(batch_size=35, data_dir='train_data/data_1', is_video=True, frame_num=15, limit=0)\n",
        "  class_weight = train_data.get_class_weight()\n",
        "  train_feature = FeatureData(1000, '/gdrive/My Drive/Colab Notebooks/fai/feature_data_1.npy', frame_num=15)\n",
        "  val_feature = FeatureData(1000, '/gdrive/My Drive/Colab Notebooks/fai/feature_data_2.npy', frame_num=15)\n",
        "  \n",
        "  hist = model.fit_generator(generator=train_feature,\n",
        "                   epochs=epochs,\n",
        "                   initial_epoch=initial_epoch,\n",
        "                   validation_data=val_feature,\n",
        "                   class_weight=class_weight,\n",
        "#                    callbacks=[model_cp]\n",
        "                  )\n",
        "  \n",
        "\n",
        "train_motion()\n",
        "\n",
        "# rnn(ボツ)\n",
        "def build_cnn_rnn_model(): # MobileNet+LSTM\n",
        "  model_input = Input(shape=(None, 224, 224, 3), name='input', dtype='float32')\n",
        "  \n",
        "  base_model = load_model('/gdrive/My Drive/Colab Notebooks/fai2/cnn_model.019-0.843.h5', compile=False)\n",
        "  mobilenet = base_model.layers[1]\n",
        "\n",
        "  net = TimeDistributed(mobilenet)(model_input)\n",
        "  net = LSTM(320, dropout=0.25, recurrent_dropout=0.25)(net)\n",
        "  net = Dense(1280, activation='relu', kernel_initializer='he_normal')(net)\n",
        "  net = Dropout(0.25)(net)\n",
        "\n",
        "  logits = Dense(class_num, activation='softmax', name='logits')(net)\n",
        "  \n",
        "  model = Model(inputs=model_input, outputs=logits)\n",
        "  model.layers[1].trainable = False\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsGTHnKtpsps",
        "colab_type": "text"
      },
      "source": [
        "# optunaさんが出した最適なハイパーパラメータ\n",
        "best_params: {'conv1_filters': 226, 'conv1_size': 3, 'conv1_padding': 'same'}  \n",
        "best_value: 0.6584836531015238\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3PjnHltxOeI",
        "colab_type": "text"
      },
      "source": [
        "# 時間で畳み込んだやつのトレーニング結果\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input (InputLayer)           (None, None, 1280)        0         \n",
        "_________________________________________________________________\n",
        "time_distributed_1 (TimeDist (None, None, 1280)        0         \n",
        "_________________________________________________________________\n",
        "conv1d_1 (Conv1D)            (None, None, 226)         868066    \n",
        "_________________________________________________________________\n",
        "batch_normalization_1 (Batch (None, None, 226)         904       \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, None, 226)         0         \n",
        "_________________________________________________________________\n",
        "global_max_pooling1d_1 (Glob (None, 226)               0         \n",
        "_________________________________________________________________\n",
        "logits (Dense)               (None, 12)                2724      \n",
        "=================================================================\n",
        "Total params: 871,694\n",
        "Trainable params: 871,242\n",
        "Non-trainable params: 452\n",
        "_________________________________________________________________\n",
        "data_dir: train_data/data_1, data_total_count=72000, split_num=2058\n",
        "Epoch 1/10\n",
        "72/72 [==============================] - 11s 146ms/step - loss: 3.4031 - acc: 0.6117 - val_loss: 0.8609 - val_acc: 0.6480\n",
        "Epoch 2/10\n",
        "72/72 [==============================] - 10s 141ms/step - loss: 1.6484 - acc: 0.7235 - val_loss: 0.7666 - val_acc: 0.6954\n",
        "Epoch 3/10\n",
        "72/72 [==============================] - 9s 132ms/step - loss: 1.3463 - acc: 0.7546 - val_loss: 0.7316 - val_acc: 0.6902\n",
        "Epoch 4/10\n",
        "72/72 [==============================] - 9s 129ms/step - loss: 1.1618 - acc: 0.7792 - val_loss: 0.8332 - val_acc: 0.6584\n",
        "Epoch 5/10\n",
        "72/72 [==============================] - 9s 127ms/step - loss: 1.0175 - acc: 0.7927 - val_loss: 0.6604 - val_acc: 0.7293\n",
        "Epoch 6/10\n",
        "72/72 [==============================] - 10s 133ms/step - loss: 0.9307 - acc: 0.8035 - val_loss: 0.7070 - val_acc: 0.7190\n",
        "Epoch 7/10\n",
        "72/72 [==============================] - 9s 128ms/step - loss: 0.8766 - acc: 0.8126 - val_loss: 0.6942 - val_acc: 0.7176\n",
        "Epoch 8/10\n",
        "72/72 [==============================] - 9s 131ms/step - loss: 0.8658 - acc: 0.8214 - val_loss: 0.7376 - val_acc: 0.7172\n",
        "Epoch 9/10\n",
        "72/72 [==============================] - 10s 132ms/step - loss: 0.7491 - acc: 0.8372 - val_loss: 0.7044 - val_acc: 0.7245\n",
        "Epoch 10/10\n",
        "72/72 [==============================] - 10s 138ms/step - loss: 0.6961 - acc: 0.8474 - val_loss: 0.7734 - val_acc: 0.7060\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjdG8xsjd35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2つをつなげて動画入力から推論までするモデルを構築して保存\n",
        "from keras import backend\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_fai_model():\n",
        "  backend.tensorflow_backend.clear_session()\n",
        "  \n",
        "  image_cnn_model = load_model('/gdrive/My Drive/Colab Notebooks/fai2/cnn_model.019-0.843.h5', compile=False)\n",
        "  frame_cnn_model = load_model('/gdrive/My Drive/Colab Notebooks/fai_motion/1dcnn_model.010-0.760.h5', compile=False)\n",
        "  \n",
        "  mobilenet = image_cnn_model.layers[1]\n",
        "\n",
        "  model_input = Input(shape=(None, 224, 224, 3), name='input', dtype='float32')\n",
        "  net = TimeDistributed(mobilenet)(model_input)\n",
        "  for layer in frame_cnn_model.layers[2:]:\n",
        "    net = layer(net)\n",
        "\n",
        "  model = Model(inputs=model_input, outputs=net)\n",
        "  return model\n",
        "\n",
        "# テストデータで性能をテスト\n",
        "def test():\n",
        "  model = build_fai_model()\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=5e-5, momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  test_data = F1Data(batch_size=50, data_dir='train_data/data_3', frame_num=15, is_video=True)\n",
        "  test_loss, test_acc = model.evaluate_generator(test_data)\n",
        "  print('test_loss: %.4f - test_acc: %.4f' % (test_loss, test_acc))\n",
        "  \n",
        "test()\n",
        "\n",
        "def save_model():\n",
        "  model = build_fai_model()\n",
        "  model.save('/gdrive/My Drive/Colab Notebooks/fai_motion/fai_model.h5', include_optimizer=False)\n",
        "\n",
        "save_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebrQHfqxxDMZ",
        "colab_type": "text"
      },
      "source": [
        "# テスト結果\n",
        "\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "input (InputLayer)           (None, None, 224, 224, 3) 0         \n",
        "_________________________________________________________________\n",
        "time_distributed_1 (TimeDist (None, None, 1280)        2257984   \n",
        "_________________________________________________________________\n",
        "conv1d_1 (Conv1D)            (None, None, 226)         868066    \n",
        "_________________________________________________________________\n",
        "batch_normalization_1 (Batch (None, None, 226)         904       \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, None, 226)         0         \n",
        "_________________________________________________________________\n",
        "global_max_pooling1d_1 (Glob (None, 226)               0         \n",
        "_________________________________________________________________\n",
        "logits (Dense)               (None, 12)                2724      \n",
        "=================================================================\n",
        "Total params: 3,129,678\n",
        "Trainable params: 3,095,114\n",
        "Non-trainable params: 34,564\n",
        "_________________________________________________________________\n",
        "data_dir: train_data/data_3, data_total_count=24587, split_num=492\n",
        "test_loss: 0.6521 - test_acc: 0.7279\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa2f63bb-acdc-4ab2-d52a-54c7f078a5f2",
        "id": "A41PGOIfeIlm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# Kerasのモデルをtensorflowのsaved_modelに変換して保存\n",
        "!rm -rf tmp_saved_model\n",
        "\n",
        "from keras import backend\n",
        "from keras.models import load_model\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "def save_as_tf():\n",
        "  backend.tensorflow_backend.clear_session()\n",
        "  \n",
        "  model = load_model('/gdrive/My Drive/Colab Notebooks/fai_motion/fai_model.h5', compile=False)\n",
        "  \n",
        "  session = backend.get_session()\n",
        "  tf.compat.v1.saved_model.simple_save(\n",
        "      session,\n",
        "      './tmp_saved_model',\n",
        "      inputs={'input': model.input},\n",
        "      outputs={'output': model.output}\n",
        "  )\n",
        "  \n",
        "save_as_tf()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-92e7c87633e0>:19: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./tmp_saved_model/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVkkEdok4MuI",
        "colab_type": "code",
        "outputId": "e9f84d53-c159-45df-de68-4890931821dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# モデル確認\n",
        "!saved_model_cli show --tag_set serve --dir tmp_saved_model\n",
        "!saved_model_cli show --tag_set serve --signature_def serving_default --dir tmp_saved_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"serving_default\"\n",
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, -1, 224, 224, 3)\n",
            "      name: input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['output'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 12)\n",
            "      name: logits/Softmax:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIhMM2hUUuRK",
        "colab_type": "code",
        "outputId": "758e9757-7be5-4883-ca66-b4ec1c2294e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# いい感じに予測ラベル値が出力になるように、直接tensorflowで弄る\n",
        "!rm -rf saved_model\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as session:\n",
        "  \n",
        "  tf.compat.v1.saved_model.loader.load(session, ['serve'], 'tmp_saved_model')\n",
        "  \n",
        "  # input\n",
        "  input_frames = session.graph.get_tensor_by_name(\"input:0\")\n",
        "  # output\n",
        "  logits = session.graph.get_tensor_by_name(\"logits/Softmax:0\")\n",
        "  predicted_label = tf.argmax(logits, 1, name='predicted_label')\n",
        "  \n",
        "\n",
        "  tf.compat.v1.saved_model.simple_save(session,\n",
        "                        './saved_model',\n",
        "                        inputs={'input': input_frames},\n",
        "                        outputs={'output': predicted_label})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-9db7588f617e>:8: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from tmp_saved_model/variables/variables\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./saved_model/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwCB-ECxhz8T",
        "colab_type": "code",
        "outputId": "2745d058-feb3-48c0-c26a-6e573d53ece5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!zip -r saved_model.zip saved_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: saved_model/ (stored 0%)\n",
            "updating: saved_model/saved_model.pb (deflated 92%)\n",
            "updating: saved_model/variables/ (stored 0%)\n",
            "updating: saved_model/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "updating: saved_model/variables/variables.index (deflated 70%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb3DQMBnag_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !cp saved_model.zip '/gdrive/My Drive/Colab Notebooks/saved_model.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}